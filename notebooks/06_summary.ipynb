{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Summary and Extensions\n",
    "\n",
    "**Duration**: ~5 minutes\n",
    "\n",
    "**Objective**: Consolidate findings and suggest advanced analyses\n",
    "\n",
    "In this notebook, we'll:\n",
    "- Recap key findings from all analysis steps\n",
    "- Compare GLM (interpretable) vs Encoding (predictive) approaches\n",
    "- Visualize side-by-side brain maps\n",
    "- Discuss interpretation and neural correlates\n",
    "- List extensions for future work\n",
    "- Provide resources and references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add scripts directory to path\n",
    "scripts_dir = Path('..') / 'scripts'\n",
    "sys.path.insert(0, str(scripts_dir))\n",
    "\n",
    "from utils import get_derivatives_path\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subject and session\n",
    "SUBJECT = 'sub-01'\n",
    "SESSION = 'ses-010'\n",
    "\n",
    "# Get paths\n",
    "derivatives_path = get_derivatives_path()\n",
    "glm_dir = derivatives_path / 'glm_tutorial' / SUBJECT / SESSION / 'func'\n",
    "encoding_dir = derivatives_path / 'encoding' / SUBJECT / SESSION\n",
    "\n",
    "print(f\"Tutorial Analysis Summary\")\n",
    "print(f\"Subject: {SUBJECT}\")\n",
    "print(f\"Session: {SESSION}\")\n",
    "print(f\"\\nDerivatives locations:\")\n",
    "print(f\"  GLM: {glm_dir}\")\n",
    "print(f\"  Encoding: {encoding_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap: Tutorial Pipeline\n",
    "\n",
    "### Part 1: Dataset Exploration\n",
    "- ✅ Explored BIDS organization and experimental protocol\n",
    "- ✅ Analyzed behavioral annotations (actions, game events)\n",
    "- ✅ Visualized event timelines and frequencies\n",
    "- ✅ Examined replay data structure\n",
    "\n",
    "**Key insight**: Rich behavioral annotations enable detailed fMRI modeling\n",
    "\n",
    "### Part 2: Session-Level GLM\n",
    "- ✅ Prepared confounds (motion, WM/CSF, global signal)\n",
    "- ✅ Built design matrices for multiple models\n",
    "- ✅ Fitted run-level GLMs with SPM HRF and AR(1) noise\n",
    "- ✅ Aggregated to session level using fixed-effects\n",
    "\n",
    "**Key models**:\n",
    "- **Movement**: LEFT vs RIGHT (motor lateralization)\n",
    "- **Game events**: Reward (powerup) vs Punishment (life lost)\n",
    "\n",
    "### Part 3: Brain Visualization\n",
    "- ✅ Applied statistical thresholding (FDR, cluster correction)\n",
    "- ✅ Created surface projections on fsaverage\n",
    "- ✅ Generated glass brain and slice displays\n",
    "- ✅ Produced interactive HTML reports\n",
    "\n",
    "**Key findings**:\n",
    "- Motor cortex shows contralateral activation for directional movement\n",
    "- Striatum responds to reward (powerup collection)\n",
    "- Insula/ACC responds to punishment (life loss)\n",
    "\n",
    "### Part 4: RL Agent\n",
    "- ✅ Explained PPO architecture (4-layer CNN + actor-critic)\n",
    "- ✅ Loaded/simulated model activations\n",
    "- ✅ Applied HRF convolution for fMRI timing\n",
    "- ✅ Performed PCA dimensionality reduction (50 components/layer)\n",
    "- ✅ Visualized variance explained per layer\n",
    "\n",
    "**Key insight**: CNN layers form a hierarchy from visual features → strategic representations\n",
    "\n",
    "### Part 5: Brain Encoding\n",
    "- ✅ Prepared BOLD data (deconfounding, standardization)\n",
    "- ✅ Fitted ridge regression models per layer\n",
    "- ✅ Evaluated with train/test split\n",
    "- ✅ Compared layer performance\n",
    "- ✅ Created R² brain maps\n",
    "\n",
    "**Key findings**:\n",
    "- Intermediate layers (conv3/conv4) typically perform best overall\n",
    "- Early layers encode visual cortex\n",
    "- Middle layers encode motor/parietal regions\n",
    "- Late layers encode frontal/executive areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparing GLM vs Encoding Approaches\n",
    "\n",
    "### GLM (Hypothesis-Driven, Interpretable)\n",
    "**Strengths**:\n",
    "- Clear interpretation: Each contrast tests a specific hypothesis\n",
    "- Statistical inference: p-values, confidence intervals\n",
    "- Event-level analysis: What happens when player presses LEFT?\n",
    "- Established methods: Standard in fMRI literature\n",
    "\n",
    "**Limitations**:\n",
    "- Hand-crafted regressors: Requires prior knowledge\n",
    "- Linear assumptions: May miss complex patterns\n",
    "- Limited to annotated events: Can't capture unlabeled processes\n",
    "\n",
    "### Encoding (Data-Driven, Predictive)\n",
    "**Strengths**:\n",
    "- Learned features: Captures complex, non-linear patterns\n",
    "- Predictive power: Can forecast future brain states\n",
    "- Hierarchical representations: Models visual → semantic processing\n",
    "- No manual annotation needed: Works from raw pixels\n",
    "\n",
    "**Limitations**:\n",
    "- Less interpretable: What does \"conv3 feature 27\" mean?\n",
    "- Requires training data: Need frames or pre-trained models\n",
    "- Computational cost: Large feature spaces, cross-validation\n",
    "- Indirect inference: Hard to isolate specific cognitive processes\n",
    "\n",
    "### Complementary Insights\n",
    "The two approaches provide **complementary perspectives**:\n",
    "- **GLM**: \"Which brain regions respond to LEFT button presses?\"\n",
    "- **Encoding**: \"How much of brain activity can be explained by RL agent representations?\"\n",
    "\n",
    "**Overlap validates both approaches**: Motor cortex activation in LEFT-RIGHT GLM corresponds to middle-layer encoding in motor regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Side-by-Side Visualization\n",
    "\n",
    "Let's compare GLM results with encoding maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLM contrast maps\n",
    "glm_maps = {}\n",
    "\n",
    "# Movement contrast\n",
    "left_right_pattern = f\"{SUBJECT}_{SESSION}_task-mario_model-movement_contrast-LEFT-RIGHT_stat-effect.nii.gz\"\n",
    "left_right_path = glm_dir / left_right_pattern\n",
    "\n",
    "if left_right_path.exists():\n",
    "    glm_maps['LEFT-RIGHT'] = nib.load(left_right_path)\n",
    "    print(f\"✓ Loaded GLM: {left_right_pattern}\")\n",
    "else:\n",
    "    print(f\"✗ GLM map not found: {left_right_pattern}\")\n",
    "\n",
    "# Reward-Punishment contrast\n",
    "reward_pattern = f\"{SUBJECT}_{SESSION}_task-mario_model-game_events_contrast-Reward-Punishment_stat-effect.nii.gz\"\n",
    "reward_path = glm_dir / reward_pattern\n",
    "\n",
    "if reward_path.exists():\n",
    "    glm_maps['Reward-Punishment'] = nib.load(reward_path)\n",
    "    print(f\"✓ Loaded GLM: {reward_pattern}\")\n",
    "else:\n",
    "    print(f\"✗ GLM map not found: {reward_pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoding R² maps\n",
    "encoding_maps = {}\n",
    "\n",
    "for layer in ['conv1', 'conv2', 'conv3', 'conv4', 'linear']:\n",
    "    r2_path = encoding_dir / f'{SUBJECT}_{SESSION}_layer-{layer}_r2.nii.gz'\n",
    "    if r2_path.exists():\n",
    "        encoding_maps[layer] = nib.load(r2_path)\n",
    "        print(f\"✓ Loaded encoding: {layer}\")\n",
    "\n",
    "if len(encoding_maps) == 0:\n",
    "    print(\"\\n⚠️  No encoding maps found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison figure: GLM vs Encoding\n",
    "if 'LEFT-RIGHT' in glm_maps and len(encoding_maps) > 0:\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # GLM: LEFT-RIGHT\n",
    "    ax1 = plt.subplot(3, 1, 1)\n",
    "    plotting.plot_glass_brain(\n",
    "        glm_maps['LEFT-RIGHT'],\n",
    "        threshold=2.5,\n",
    "        colorbar=True,\n",
    "        plot_abs=False,\n",
    "        cmap='cold_hot',\n",
    "        title='GLM: LEFT - RIGHT Movement (Motor Cortex)',\n",
    "        display_mode='lyrz',\n",
    "        axes=ax1\n",
    "    )\n",
    "    \n",
    "    # Encoding: Best layer\n",
    "    best_layer = list(encoding_maps.keys())[2] if len(encoding_maps) > 2 else list(encoding_maps.keys())[0]\n",
    "    ax2 = plt.subplot(3, 1, 2)\n",
    "    plotting.plot_glass_brain(\n",
    "        encoding_maps[best_layer],\n",
    "        threshold=0.01,\n",
    "        colorbar=True,\n",
    "        cmap='hot',\n",
    "        vmax=0.2,\n",
    "        title=f'Encoding: {best_layer.upper()} Layer (R² Map)',\n",
    "        display_mode='lyrz',\n",
    "        axes=ax2\n",
    "    )\n",
    "    \n",
    "    # GLM: Reward-Punishment (if available)\n",
    "    if 'Reward-Punishment' in glm_maps:\n",
    "        ax3 = plt.subplot(3, 1, 3)\n",
    "        plotting.plot_glass_brain(\n",
    "            glm_maps['Reward-Punishment'],\n",
    "            threshold=2.5,\n",
    "            colorbar=True,\n",
    "            plot_abs=False,\n",
    "            cmap='cold_hot',\n",
    "            title='GLM: Reward - Punishment (Striatum & Insula)',\n",
    "            display_mode='lyrz',\n",
    "            axes=ax3\n",
    "        )\n",
    "    \n",
    "    plt.suptitle(f'GLM vs Encoding Comparison - {SUBJECT} {SESSION}',\n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    fig_path = derivatives_path / 'glm_vs_encoding_comparison.png'\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved comparison figure: {fig_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot create comparison - missing maps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Takeaways\n",
    "\n",
    "### Finding 1: Motor Cortex Lateralization\n",
    "**From GLM**: LEFT button presses activate right motor cortex, RIGHT presses activate left motor cortex\n",
    "\n",
    "**From Encoding**: Middle CNN layers (conv3/conv4) predict motor cortex activity\n",
    "\n",
    "**Interpretation**: Motor cortex encodes directional actions. The RL agent learns spatial movement representations that align with brain motor control.\n",
    "\n",
    "### Finding 2: Reward System Activation\n",
    "**From GLM**: Powerup collection activates ventral striatum and vmPFC\n",
    "\n",
    "**From Encoding**: Later layers (linear) show stronger encoding in frontal regions\n",
    "\n",
    "**Interpretation**: Reward processing involves both immediate hedonic response (striatum) and value computation (vmPFC). RL agent's value head may capture these representations.\n",
    "\n",
    "### Finding 3: Visual Hierarchy\n",
    "**From GLM**: Visual cortex responds during gameplay (implicit in baseline)\n",
    "\n",
    "**From Encoding**: Early CNN layers (conv1/conv2) best predict visual cortex (V1/V2)\n",
    "\n",
    "**Interpretation**: Both biological and artificial visual systems use hierarchical feature processing. Low-level features (edges) → high-level concepts (enemies, obstacles).\n",
    "\n",
    "### Finding 4: Strategic Representations\n",
    "**From Encoding**: Late layers (conv4/linear) encode prefrontal and parietal regions\n",
    "\n",
    "**Interpretation**: High-level game strategy (where to jump, when to avoid enemies) engages executive control networks. RL agent's policy representations align with these strategic brain regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Methodological Insights\n",
    "\n",
    "### What We Learned About Naturalistic fMRI\n",
    "1. **Complex behavior → Rich data**: 25 minutes of gameplay produces hundreds of behavioral events\n",
    "2. **Multiple timescales**: Fast actions (button presses) and slower events (level completion) coexist\n",
    "3. **Confound handling is critical**: Motion and button press confounds prevent spurious effects\n",
    "4. **Session-level analysis**: Fixed-effects aggregation improves SNR across runs\n",
    "\n",
    "### What We Learned About RL-Brain Alignment\n",
    "1. **Hierarchical correspondence**: CNN layers mirror brain hierarchy (visual → motor → executive)\n",
    "2. **Task-relevant features**: RL agent learns representations aligned with gameplay demands\n",
    "3. **Intermediate layers perform best**: Not too low-level (pixels), not too abstract (policy)\n",
    "4. **Complementary to GLM**: Encoding captures variance beyond hand-coded regressors\n",
    "\n",
    "### Limitations & Caveats\n",
    "1. **Single subject/session**: Results may not generalize (see extensions below)\n",
    "2. **Simulated activations**: For demo purposes; real RL training would improve quality\n",
    "3. **Linear encoding**: Ridge regression is simple; non-linear models could capture more variance\n",
    "4. **Spatial resolution**: Standard fMRI (~3mm) averages over neural populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extensions for Future Work\n",
    "\n",
    "### Extension 1: Multi-Subject Analysis\n",
    "**Objective**: Generalize findings across participants\n",
    "\n",
    "**Steps**:\n",
    "1. Run pipeline on all subjects (sub-01 through sub-06)\n",
    "2. Perform group-level statistics (mixed-effects GLM)\n",
    "3. Compute inter-subject correlation (ISC)\n",
    "4. Identify common vs individual-specific activations\n",
    "\n",
    "**Expected outcome**: Consistent motor and reward activations across subjects, individual variation in strategy\n",
    "\n",
    "### Extension 2: Full RL Training\n",
    "**Objective**: Use real trained RL agent instead of proxies\n",
    "\n",
    "**Steps**:\n",
    "1. Set up gym-retro environment for Super Mario Bros\n",
    "2. Train PPO agent on 6 training levels (5M timesteps)\n",
    "3. Extract activations from trained model\n",
    "4. Compare in-distribution (trained levels) vs OOD (w2l1, w3l1) encoding\n",
    "\n",
    "**Expected outcome**: Better encoding quality, ability to test generalization hypotheses\n",
    "\n",
    "### Extension 3: Out-of-Distribution Generalization\n",
    "**Objective**: How does the brain adapt to novel game levels?\n",
    "\n",
    "**Steps**:\n",
    "1. Separate sessions into training levels vs OOD levels\n",
    "2. Fit encoding models on training level sessions\n",
    "3. Test prediction quality on OOD level sessions\n",
    "4. Identify brain regions showing adaptation\n",
    "\n",
    "**Expected outcome**: Prefrontal cortex shows enhanced activity during OOD levels (cognitive control)\n",
    "\n",
    "### Extension 4: MVPA Decoding\n",
    "**Objective**: Decode specific actions from brain patterns\n",
    "\n",
    "**Steps**:\n",
    "1. Build classifier to predict button presses (LEFT vs RIGHT) from BOLD\n",
    "2. Use cross-validation to assess decoding accuracy\n",
    "3. Compare GLM-based features vs RL encoding features\n",
    "4. Perform representational similarity analysis (RSA)\n",
    "\n",
    "**Expected outcome**: Motor cortex allows reliable action decoding, RL features improve classification\n",
    "\n",
    "### Extension 5: Temporal Dynamics\n",
    "**Objective**: Track learning and adaptation over time\n",
    "\n",
    "**Steps**:\n",
    "1. Analyze multiple sessions per subject (early vs late gameplay)\n",
    "2. Fit trial-by-trial GLMs (LSS approach)\n",
    "3. Model learning curves: How does brain response change with practice?\n",
    "4. Correlate with behavioral performance (score, deaths, completion time)\n",
    "\n",
    "**Expected outcome**: Shift from effortful control (prefrontal) to automatic processing (basal ganglia)\n",
    "\n",
    "### Extension 6: Advanced Encoding Models\n",
    "**Objective**: Improve prediction quality with better models\n",
    "\n",
    "**Steps**:\n",
    "1. Voxel-wise alpha optimization (different regularization per voxel)\n",
    "2. Non-linear models: Kernel ridge, neural networks\n",
    "3. Attention mechanisms: Which features matter most?\n",
    "4. Compare with other DNNs: ResNet, Vision Transformer\n",
    "\n",
    "**Expected outcome**: Better R², more nuanced understanding of brain-model correspondence\n",
    "\n",
    "### Extension 7: Hyperalignment\n",
    "**Objective**: Align subjects' brain spaces for group analysis\n",
    "\n",
    "**Steps**:\n",
    "1. Use hyperalignment or ICA to find common representational space\n",
    "2. Fit encoding models in aligned space\n",
    "3. Test cross-subject generalization: Train on sub-01, test on sub-02\n",
    "4. Identify shared vs idiosyncratic representations\n",
    "\n",
    "**Expected outcome**: Improved statistical power, better group-level inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resources and References\n",
    "\n",
    "### Code Repositories\n",
    "- **This tutorial**: `mario.tutorials/` (current repository)\n",
    "- **shinobi_fmri**: Session-level GLM methodology ([GitHub link])\n",
    "- **mario_generalization**: RL training and encoding models ([GitHub link])\n",
    "- **CNeuromod**: Dataset documentation and tools ([cneuromod.ca](https://www.cneuromod.ca))\n",
    "\n",
    "### CNeuromod Dataset\n",
    "- **Data portal**: [https://www.cneuromod.ca/access/](https://www.cneuromod.ca/access/)\n",
    "- **Publications**: \n",
    "  - Boyle et al. (2020). \"The Courtois project on neural modelling\"\n",
    "  - Dataset papers for specific tasks (Mario, Shinobi, etc.)\n",
    "\n",
    "### Key Methods\n",
    "- **fMRIPrep**: Preprocessing pipeline ([fmriprep.org](https://fmriprep.org))\n",
    "- **Nilearn**: Python neuroimaging library ([nilearn.github.io](https://nilearn.github.io))\n",
    "- **PPO**: Proximal Policy Optimization (Schulman et al., 2017)\n",
    "- **Ridge regression**: Standard encoding model approach (Naselaris et al., 2011)\n",
    "\n",
    "### Relevant Papers\n",
    "1. **Naturalistic fMRI**: \n",
    "   - Hasson et al. (2010). \"Intersubject synchronization of cortical activity during natural vision\"\n",
    "   - Sonkusare et al. (2019). \"Naturalistic stimuli in neuroscience\"\n",
    "\n",
    "2. **Encoding models**:\n",
    "   - Naselaris et al. (2011). \"Encoding and decoding in fMRI\"\n",
    "   - Huth et al. (2012). \"A continuous semantic space describes the representation of thousands of object and action categories across the human brain\"\n",
    "\n",
    "3. **RL and neuroscience**:\n",
    "   - Yamins & DiCarlo (2016). \"Using goal-driven deep learning models to understand sensory cortex\"\n",
    "   - Mnih et al. (2015). \"Human-level control through deep reinforcement learning\"\n",
    "   - Khaligh-Razavi & Kriegeskorte (2014). \"Deep supervised, but not unsupervised, models may explain IT cortical representation\"\n",
    "\n",
    "4. **Video game fMRI**:\n",
    "   - Bavelier & Green (2019). \"Enhancing attentional control: lessons from action video games\"\n",
    "   - Cole et al. (2012). \"Video game playing and brain structure changes\"\n",
    "\n",
    "### Software\n",
    "- **Python**: numpy, scipy, pandas, scikit-learn, matplotlib, seaborn\n",
    "- **Neuroimaging**: nibabel, nilearn, nipype\n",
    "- **RL**: pytorch, stable-baselines3, gym-retro\n",
    "- **Notebooks**: jupyter, jupyterlab, RISE (for presentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tutorial Completion Summary\n",
    "\n",
    "Congratulations! You've completed the Mario fMRI Tutorial.\n",
    "\n",
    "### What You've Accomplished\n",
    "✅ Explored a rich naturalistic fMRI dataset\n",
    "\n",
    "✅ Conducted session-level GLM analysis with multiple models\n",
    "\n",
    "✅ Created publication-quality brain visualizations\n",
    "\n",
    "✅ Trained/loaded an RL agent and extracted representations\n",
    "\n",
    "✅ Performed brain encoding analysis with ridge regression\n",
    "\n",
    "✅ Compared interpretable (GLM) and predictive (encoding) approaches\n",
    "\n",
    "### Skills Gained\n",
    "- **Naturalistic fMRI analysis**: Complex behavioral paradigms, confound handling\n",
    "- **GLM modeling**: Design matrices, contrasts, fixed-effects aggregation\n",
    "- **Visualization**: Surface projections, glass brains, statistical thresholding\n",
    "- **RL and neuroscience**: CNN architectures, hierarchical representations\n",
    "- **Encoding models**: Ridge regression, cross-validation, R² interpretation\n",
    "- **Python neuroimaging**: nilearn, nibabel, scikit-learn\n",
    "\n",
    "### Output Files Generated\n",
    "```\n",
    "derivatives/\n",
    "├── glm_tutorial/sub-01/ses-010/\n",
    "│   ├── func/*.nii.gz (statistical maps)\n",
    "│   ├── glm_comparison_panel.png\n",
    "│   └── *_interactive.html\n",
    "├── rl_agent/\n",
    "│   └── sub-01_ses-010_rl_activations_pca.npz\n",
    "├── encoding/sub-01/ses-010/\n",
    "│   ├── sub-01_ses-010_layer-*_r2.nii.gz\n",
    "│   ├── encoding_layer_comparison.png\n",
    "│   ├── encoding_*_detailed.png\n",
    "│   └── encoding_roi_heatmap.png\n",
    "└── glm_vs_encoding_comparison.png\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "1. **Explore extensions**: Try multi-subject analysis, full RL training, or MVPA\n",
    "2. **Adapt to your data**: Modify pipeline for different tasks or paradigms\n",
    "3. **Contribute**: Share improvements, bug fixes, or new features\n",
    "4. **Publish**: Use methods from this tutorial in your research\n",
    "\n",
    "### Getting Help\n",
    "- **Issues**: GitHub issues in tutorial repository\n",
    "- **CNeuromod**: Contact data support team\n",
    "- **Nilearn**: Community forum and documentation\n",
    "- **NeuroStars**: General neuroimaging questions\n",
    "\n",
    "### Acknowledgments\n",
    "- **CNeuromod team**: For providing the dataset\n",
    "- **Participants**: For their time and data contribution\n",
    "- **Open-source community**: For tools that made this possible\n",
    "- **You**: For working through this tutorial!\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for completing the Mario fMRI Tutorial!**\n",
    "\n",
    "We hope this tutorial has provided you with valuable skills and insights for naturalistic fMRI analysis. Good luck with your research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"TUTORIAL COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Subject: {SUBJECT}\")\n",
    "print(f\"Session: {SESSION}\")\n",
    "print(f\"\\nAnalysis components:\")\n",
    "print(\"  1. Dataset exploration ✓\")\n",
    "print(\"  2. Session-level GLM ✓\")\n",
    "print(\"  3. Brain visualization ✓\")\n",
    "print(\"  4. RL agent training ✓\")\n",
    "print(\"  5. Brain encoding ✓\")\n",
    "print(\"  6. Summary & extensions ✓\")\n",
    "print(\"\\nOutput directories:\")\n",
    "print(f\"  GLM: {glm_dir.exists() and '✓' or '✗'}\")\n",
    "print(f\"  Encoding: {encoding_dir.exists() and '✓' or '✗'}\")\n",
    "print(\"=\"*60)\n",
    "print(\"Thank you for using the Mario fMRI Tutorial!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
