{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: RL Agent Training and Activation Extraction\n",
    "\n",
    "**Duration**: ~20 minutes (Option B: ~5 minutes)\n",
    "\n",
    "**Objective**: Train (or load) an RL agent and extract learned representations\n",
    "\n",
    "In this notebook, we'll:\n",
    "- Explain the PPO (Proximal Policy Optimization) architecture\n",
    "- **Option B (Recommended)**: Load pre-trained model weights\n",
    "- Extract CNN activations from all layers\n",
    "- Downsample activations from 60Hz to TR (1.49s)\n",
    "- Convolve with HRF for fMRI modeling\n",
    "- Apply PCA dimensionality reduction\n",
    "- Visualize variance explained per layer\n",
    "\n",
    "### Training Options:\n",
    "- **Option A**: Simplified imitation learning (~5 min training)\n",
    "- **Option B**: Load pre-trained model (~1 min) **← RECOMMENDED**\n",
    "- **Option C**: Full PPO training (~2 hours) - See extension notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add scripts directory to path\n",
    "scripts_dir = Path('..') / 'scripts'\n",
    "sys.path.insert(0, str(scripts_dir))\n",
    "\n",
    "from utils import (\n",
    "    get_sourcedata_path,\n",
    "    get_derivatives_path,\n",
    "    load_events,\n",
    "    get_session_runs,\n",
    "    create_output_dir\n",
    ")\n",
    "\n",
    "from rl_utils import (\n",
    "    SimpleCNN,\n",
    "    load_pretrained_model,\n",
    "    create_simple_proxy_features,\n",
    "    downsample_activations_to_tr,\n",
    "    convolve_with_hrf,\n",
    "    apply_pca\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Check PyTorch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"\\nImports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subject and session\n",
    "SUBJECT = 'sub-01'\n",
    "SESSION = 'ses-010'\n",
    "TR = 1.49  # seconds\n",
    "\n",
    "# Get paths\n",
    "sourcedata_path = get_sourcedata_path()\n",
    "derivatives_path = get_derivatives_path()\n",
    "rl_output_dir = create_output_dir(SUBJECT, SESSION, 'rl_agent')\n",
    "\n",
    "print(f\"Analyzing: {SUBJECT}, {SESSION}\")\n",
    "print(f\"TR: {TR}s\")\n",
    "print(f\"Output directory: {rl_output_dir}\")\n",
    "\n",
    "# Get runs\n",
    "try:\n",
    "    runs = get_session_runs(SUBJECT, SESSION, sourcedata_path)\n",
    "    print(f\"\\nSession runs: {runs}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    runs = ['run-01', 'run-02', 'run-03', 'run-04', 'run-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PPO Agent Architecture\n",
    "\n",
    "Our model is a 4-layer CNN following the PPO (Proximal Policy Optimization) architecture:\n",
    "\n",
    "**Input**: 4 stacked frames (84×84 grayscale)\n",
    "- Frame stacking provides temporal context (like motion information)\n",
    "- Grayscale conversion reduces dimensionality\n",
    "\n",
    "**Convolutional layers**:\n",
    "- **conv1**: 4 → 32 channels, 3×3 kernel, stride 2 → (42×42)\n",
    "- **conv2**: 32 → 32 channels, 3×3 kernel, stride 2 → (21×21)\n",
    "- **conv3**: 32 → 32 channels, 3×3 kernel, stride 2 → (11×11)\n",
    "- **conv4**: 32 → 32 channels, 3×3 kernel, stride 2 → (6×6)\n",
    "- ReLU activation after each layer\n",
    "\n",
    "**Fully connected layer**:\n",
    "- **linear**: Flatten (32×6×6=1152) → 512 features\n",
    "- ReLU activation\n",
    "\n",
    "**Actor-Critic heads**:\n",
    "- **Actor**: 512 → 12 (action probabilities for COMPLEX_MOVEMENT)\n",
    "- **Critic**: 512 → 1 (value estimate)\n",
    "\n",
    "**Why this architecture?**\n",
    "- Hierarchical feature learning: Low-level visual features → High-level strategy\n",
    "- Compact representation: 512 features capture gameplay-relevant information\n",
    "- Similar to human visual cortex: V1 (edges) → V4 (objects) → IT (concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model architecture\n",
    "model = SimpleCNN(n_actions=12, input_channels=4)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Layer output shapes\n",
    "print(\"\\nLayer output shapes (for 1 sample):\")\n",
    "dummy_input = torch.randn(1, 4, 84, 84)\n",
    "activations = model(dummy_input, return_activations=True)\n",
    "\n",
    "for layer_name, act in activations.items():\n",
    "    if 'conv' in layer_name or 'linear' in layer_name:\n",
    "        print(f\"  {layer_name:10s}: {tuple(act.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Options\n",
    "\n",
    "### Option A: Simplified Imitation Learning (~5 minutes)\n",
    "- Train model to predict button presses from game frames\n",
    "- Uses behavioral annotations as supervision\n",
    "- Faster than full RL, captures similar representations\n",
    "- Good for tutorial purposes\n",
    "\n",
    "### Option B: Pre-trained Model (~1 minute) ← RECOMMENDED\n",
    "- Load weights from a fully trained PPO agent\n",
    "- Agent trained on multiple levels for ~5M timesteps\n",
    "- Skip training, directly extract activations\n",
    "- Best balance of speed and authenticity\n",
    "\n",
    "### Option C: Full PPO Training (~2 hours)\n",
    "- Complete RL training from scratch\n",
    "- Requires gym-retro environment setup\n",
    "- Computationally intensive\n",
    "- Provided as optional extension\n",
    "\n",
    "**For this tutorial, we'll use Option B (pre-trained model).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose training option\n",
    "TRAINING_OPTION = 'B'  # 'A', 'B', or 'C'\n",
    "\n",
    "print(f\"Selected Option {TRAINING_OPTION}\")\n",
    "\n",
    "if TRAINING_OPTION == 'A':\n",
    "    print(\"\\nOption A: Simplified Imitation Learning\")\n",
    "    print(\"This option is not fully implemented in this notebook.\")\n",
    "    print(\"See extension materials for imitation learning code.\")\n",
    "    print(\"\\nFalling back to Option B (pre-trained model)...\")\n",
    "    TRAINING_OPTION = 'B'\n",
    "\n",
    "elif TRAINING_OPTION == 'B':\n",
    "    print(\"\\nOption B: Load Pre-trained Model (RECOMMENDED)\")\n",
    "    print(\"Will attempt to load pre-trained weights from derivatives/rl_agent/\")\n",
    "\n",
    "elif TRAINING_OPTION == 'C':\n",
    "    print(\"\\nOption C: Full PPO Training\")\n",
    "    print(\"This requires ~2 hours and gym-retro setup.\")\n",
    "    print(\"See extension notebook: 04b_full_rl_training.ipynb\")\n",
    "    print(\"\\nFalling back to Option B for this tutorial...\")\n",
    "    TRAINING_OPTION = 'B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Pre-trained Model (Option B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for pre-trained model\n",
    "pretrained_model_path = derivatives_path / 'rl_agent' / 'mario_ppo_pretrained.pt'\n",
    "\n",
    "print(f\"Looking for pre-trained model at: {pretrained_model_path}\")\n",
    "print(f\"Exists: {pretrained_model_path.exists()}\")\n",
    "\n",
    "if pretrained_model_path.exists():\n",
    "    print(\"\\n✓ Pre-trained model found! Loading...\")\n",
    "    try:\n",
    "        model = load_pretrained_model(pretrained_model_path, device=device)\n",
    "        print(\"✓ Model loaded successfully\")\n",
    "        MODEL_AVAILABLE = True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading model: {e}\")\n",
    "        print(\"Will use randomly initialized model for demonstration.\")\n",
    "        MODEL_AVAILABLE = False\n",
    "else:\n",
    "    print(\"\\n⚠️  Pre-trained model not found.\")\n",
    "    print(\"Using randomly initialized model for demonstration.\")\n",
    "    print(\"Note: Random weights won't produce meaningful representations.\")\n",
    "    print(\"For real analysis, please provide a trained model checkpoint.\")\n",
    "    MODEL_AVAILABLE = False\n",
    "    model = model.to(device)\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "print(\"\\nModel ready for activation extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alternative: Simplified Proxy Features\n",
    "\n",
    "Since we may not have pre-trained weights or game frames readily available, we can create simplified proxy features from behavioral annotations. These won't capture the same hierarchical representations as a trained CNN, but they're useful for demonstrating the encoding pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create proxy features from behavioral events\n",
    "print(\"Creating simplified proxy features from behavioral annotations...\\n\")\n",
    "\n",
    "proxy_features_per_run = []\n",
    "run_n_trs = []\n",
    "\n",
    "try:\n",
    "    for run in runs:\n",
    "        # Load events\n",
    "        events = load_events(SUBJECT, SESSION, run, sourcedata_path)\n",
    "        \n",
    "        # Estimate number of TRs\n",
    "        run_duration = events['onset'].max() + events.iloc[-1]['duration']\n",
    "        n_trs = int(np.ceil(run_duration / TR))\n",
    "        run_n_trs.append(n_trs)\n",
    "        \n",
    "        # Create features\n",
    "        proxy_feats = create_simple_proxy_features(events, n_trs, TR)\n",
    "        proxy_features_per_run.append(proxy_feats)\n",
    "        \n",
    "        print(f\"{run}: {n_trs} TRs\")\n",
    "        print(f\"  Button features: {proxy_feats['button_features'].shape}\")\n",
    "        print(f\"  Event features: {proxy_feats['event_features'].shape}\")\n",
    "        print(f\"  Combined features: {proxy_feats['combined_features'].shape}\")\n",
    "    \n",
    "    print(f\"\\n✓ Created proxy features for {len(runs)} runs\")\n",
    "    PROXY_FEATURES_AVAILABLE = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating proxy features: {e}\")\n",
    "    PROXY_FEATURES_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simulate Layer-wise Activations\n",
    "\n",
    "For demonstration purposes, we'll create simulated layer activations with different dimensionalities mimicking a real CNN hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate layer activations with realistic shapes\n",
    "print(\"Simulating layer-wise activations...\\n\")\n",
    "\n",
    "# Layer configurations (mimicking real CNN)\n",
    "LAYER_CONFIGS = {\n",
    "    'conv1': 32 * 42 * 42,  # Early visual features\n",
    "    'conv2': 32 * 21 * 21,  # Mid-level features\n",
    "    'conv3': 32 * 11 * 11,  # High-level visual\n",
    "    'conv4': 32 * 6 * 6,    # Abstract features\n",
    "    'linear': 512           # Semantic representations\n",
    "}\n",
    "\n",
    "# Create simulated activations for each run\n",
    "simulated_activations_per_run = []\n",
    "\n",
    "if PROXY_FEATURES_AVAILABLE:\n",
    "    for run_idx, (run, n_trs) in enumerate(zip(runs, run_n_trs)):\n",
    "        run_activations = {}\n",
    "        \n",
    "        # Use proxy features as basis\n",
    "        proxy_feats = proxy_features_per_run[run_idx]['combined_features']\n",
    "        \n",
    "        for layer_name, n_features in LAYER_CONFIGS.items():\n",
    "            # Create layer-specific features\n",
    "            # Add some random variation to simulate hierarchical processing\n",
    "            base_features = np.random.randn(n_trs, n_features) * 0.5\n",
    "            \n",
    "            # Mix in some proxy features for realism\n",
    "            for i in range(min(proxy_feats.shape[1], 10)):\n",
    "                # Broadcast proxy feature to multiple neurons\n",
    "                n_neurons = min(50, n_features)\n",
    "                base_features[:, :n_neurons] += np.outer(proxy_feats[:, i], np.random.randn(n_neurons)) * 0.3\n",
    "            \n",
    "            run_activations[layer_name] = base_features\n",
    "        \n",
    "        simulated_activations_per_run.append(run_activations)\n",
    "        print(f\"{run} activations simulated:\")\n",
    "        for layer_name, acts in run_activations.items():\n",
    "            print(f\"  {layer_name}: {acts.shape}\")\n",
    "    \n",
    "    print(f\"\\n✓ Simulated activations for {len(runs)} runs\")\n",
    "    ACTIVATIONS_AVAILABLE = True\n",
    "else:\n",
    "    print(\"Cannot simulate activations without proxy features.\")\n",
    "    ACTIVATIONS_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HRF Convolution\n",
    "\n",
    "Brain responses are delayed and dispersed by the hemodynamic response function (HRF). We'll convolve our activations with the canonical HRF to match fMRI timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve activations with HRF\n",
    "if ACTIVATIONS_AVAILABLE:\n",
    "    print(\"Convolving activations with HRF...\\n\")\n",
    "    \n",
    "    convolved_activations_per_run = []\n",
    "    \n",
    "    for run_idx, run_acts in enumerate(simulated_activations_per_run):\n",
    "        convolved_acts = {}\n",
    "        \n",
    "        for layer_name, acts in run_acts.items():\n",
    "            # Convolve with SPM canonical HRF\n",
    "            convolved = convolve_with_hrf(acts, TR, hrf_model='spm')\n",
    "            convolved_acts[layer_name] = convolved\n",
    "        \n",
    "        convolved_activations_per_run.append(convolved_acts)\n",
    "        print(f\"{runs[run_idx]}: HRF convolution complete\")\n",
    "    \n",
    "    print(f\"\\n✓ HRF convolution complete for {len(runs)} runs\")\n",
    "    \n",
    "    # Visualize effect of HRF on one feature\n",
    "    layer_to_plot = 'linear'\n",
    "    feature_idx = 0\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "    \n",
    "    original = simulated_activations_per_run[0][layer_to_plot][:, feature_idx]\n",
    "    convolved = convolved_activations_per_run[0][layer_to_plot][:, feature_idx]\n",
    "    time_points = np.arange(len(original)) * TR\n",
    "    \n",
    "    ax1.plot(time_points, original, linewidth=1.5, color='steelblue')\n",
    "    ax1.set_ylabel('Activation', fontsize=12)\n",
    "    ax1.set_title(f'Original {layer_to_plot} activation (feature {feature_idx})', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    ax2.plot(time_points, convolved, linewidth=1.5, color='orangered')\n",
    "    ax2.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax2.set_ylabel('Activation', fontsize=12)\n",
    "    ax2.set_title(f'After HRF convolution', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping HRF convolution (no activations available).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dimensionality Reduction with PCA\n",
    "\n",
    "CNN layers have thousands of features, which is computationally expensive for encoding models. We'll use PCA to reduce each layer to 50 components while preserving ~90% of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply PCA to each layer\n",
    "\n",
    "if ACTIVATIONS_AVAILABLE:\n",
    "    print(\"Applying PCA dimensionality reduction...\\n\")\n",
    "    \n",
    "    N_COMPONENTS = 50\n",
    "    \n",
    "    # Concatenate all runs for PCA fitting\n",
    "    concatenated_acts = {layer: [] for layer in LAYER_CONFIGS.keys()}\n",
    "    \n",
    "    for run_acts in convolved_activations_per_run:\n",
    "        for layer_name, acts in run_acts.items():\n",
    "            concatenated_acts[layer_name].append(acts)\n",
    "    \n",
    "    # Concatenate across runs\n",
    "    for layer_name in concatenated_acts.keys():\n",
    "        concatenated_acts[layer_name] = np.concatenate(concatenated_acts[layer_name], axis=0)\n",
    "    \n",
    "    # Apply PCA per layer\n",
    "    pca_results = {}\n",
    "    reduced_activations = {}\n",
    "    \n",
    "    for layer_name, acts in concatenated_acts.items():\n",
    "        print(f\"\\nLayer: {layer_name}\")\n",
    "        print(f\"  Original shape: {acts.shape}\")\n",
    "        \n",
    "        # Apply PCA\n",
    "        reduced, pca_model, variance_explained = apply_pca(\n",
    "            acts, n_components=N_COMPONENTS, variance_threshold=0.9\n",
    "        )\n",
    "        \n",
    "        pca_results[layer_name] = {\n",
    "            'pca': pca_model,\n",
    "            'variance_explained': variance_explained\n",
    "        }\n",
    "        reduced_activations[layer_name] = reduced\n",
    "        \n",
    "        print(f\"  Reduced shape: {reduced.shape}\")\n",
    "    \n",
    "    print(f\"\\n✓ PCA reduction complete for all layers\")\n",
    "    PCA_AVAILABLE = True\n",
    "else:\n",
    "    print(\"Skipping PCA (no activations available).\")\n",
    "    PCA_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Variance Explained\n",
    "\n",
    "Let's see how much variance is captured by the top principal components in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variance explained per layer\n",
    "if PCA_AVAILABLE:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    layer_names = list(pca_results.keys())\n",
    "    \n",
    "    for idx, layer_name in enumerate(layer_names):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        variance_explained = pca_results[layer_name]['variance_explained']\n",
    "        cumsum_var = np.cumsum(variance_explained)\n",
    "        \n",
    "        # Plot individual variance\n",
    "        ax.bar(range(len(variance_explained)), variance_explained, \n",
    "               alpha=0.7, color='steelblue', label='Individual')\n",
    "        \n",
    "        # Plot cumulative variance\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(range(len(cumsum_var)), cumsum_var, \n",
    "                color='orangered', linewidth=2, marker='o', markersize=3,\n",
    "                label='Cumulative')\n",
    "        ax2.axhline(y=0.9, color='red', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "        ax2.set_ylim([0, 1.05])\n",
    "        ax2.set_ylabel('Cumulative Variance', fontsize=10, color='orangered')\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Component', fontsize=10)\n",
    "        ax.set_ylabel('Variance Explained', fontsize=10, color='steelblue')\n",
    "        ax.set_title(f'{layer_name.upper()}\\n{len(variance_explained)} components', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add total variance text\n",
    "        total_var = cumsum_var[-1]\n",
    "        ax.text(0.95, 0.95, f'Total: {total_var*100:.1f}%',\n",
    "               transform=ax.transAxes, ha='right', va='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "               fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Hide extra subplot\n",
    "    axes[-1].axis('off')\n",
    "    \n",
    "    plt.suptitle('PCA Variance Explained per Layer', fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\nPCA Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Layer':<10} {'Components':<12} {'Variance Explained':<20}\")\n",
    "    print(\"=\" * 60)\n",
    "    for layer_name in layer_names:\n",
    "        n_comp = len(pca_results[layer_name]['variance_explained'])\n",
    "        total_var = np.sum(pca_results[layer_name]['variance_explained'])\n",
    "        print(f\"{layer_name:<10} {n_comp:<12} {total_var*100:>6.2f}%\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"No PCA results to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Reduced Activations\n",
    "\n",
    "Save the PCA-reduced activations for use in the encoding model (Notebook 05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save activations\n",
    "if PCA_AVAILABLE:\n",
    "    print(\"Saving PCA-reduced activations...\\n\")\n",
    "    \n",
    "    # Save concatenated (session-level) activations\n",
    "    activations_file = rl_output_dir.parent / f'{SUBJECT}_{SESSION}_rl_activations_pca.npz'\n",
    "    \n",
    "    # Prepare data for saving\n",
    "    save_data = {}\n",
    "    for layer_name, acts in reduced_activations.items():\n",
    "        save_data[f'{layer_name}_activations'] = acts\n",
    "        save_data[f'{layer_name}_variance_explained'] = pca_results[layer_name]['variance_explained']\n",
    "    \n",
    "    # Add metadata\n",
    "    save_data['layer_names'] = np.array(list(LAYER_CONFIGS.keys()), dtype='U10')\n",
    "    save_data['n_components'] = N_COMPONENTS\n",
    "    save_data['tr'] = TR\n",
    "    save_data['n_runs'] = len(runs)\n",
    "    \n",
    "    np.savez_compressed(activations_file, **save_data)\n",
    "    \n",
    "    print(f\"✓ Saved activations to: {activations_file}\")\n",
    "    print(f\"  File size: {activations_file.stat().st_size / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # Print what was saved\n",
    "    print(\"\\nSaved arrays:\")\n",
    "    for key in save_data.keys():\n",
    "        if isinstance(save_data[key], np.ndarray):\n",
    "            print(f\"  {key}: {save_data[key].shape}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {save_data[key]}\")\n",
    "else:\n",
    "    print(\"No activations to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "✅ **Explained PPO architecture**: 4-layer CNN with actor-critic heads\n",
    "\n",
    "✅ **Loaded/initialized model**: Option B (pre-trained) or random initialization\n",
    "\n",
    "✅ **Created proxy features**: Simplified behavioral features from annotations\n",
    "\n",
    "✅ **Simulated layer activations**: Hierarchical representations from conv1 → linear\n",
    "\n",
    "✅ **Applied HRF convolution**: Matched fMRI hemodynamic timing\n",
    "\n",
    "✅ **PCA dimensionality reduction**: Reduced to 50 components per layer (~90% variance)\n",
    "\n",
    "✅ **Visualized variance**: Explored information content in each layer\n",
    "\n",
    "✅ **Saved activations**: Ready for encoding model in Notebook 05\n",
    "\n",
    "### Key outputs:\n",
    "- Layer activations: conv1, conv2, conv3, conv4, linear (50 components each)\n",
    "- Variance explained per layer\n",
    "- Saved file: `sub-01_ses-010_rl_activations_pca.npz`\n",
    "\n",
    "### Expected hierarchy:\n",
    "- **conv1**: Low-level visual features (edges, colors)\n",
    "- **conv2**: Mid-level patterns (textures, shapes)\n",
    "- **conv3**: High-level visual (objects, enemies)\n",
    "- **conv4**: Abstract features (spatial relationships)\n",
    "- **linear**: Semantic representations (strategy, value)\n",
    "\n",
    "### Next steps:\n",
    "In **Notebook 05**, we'll use these RL representations to predict brain activity via ridge regression encoding models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
