{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mario fMRI Tutorial\n## Complete Analysis Pipeline: From GLM to Brain Encoding\n\n<br>\n\n### Overview of the CNeuromod Mario Dataset\n\n**What we'll cover:**\n- Dataset exploration and behavioral annotations\n- GLM analysis: Actions and game events\n- RL agent: Learning representations from gameplay\n- Brain encoding: Predicting fMRI from learned features\n\n<br>\n\n---\n\n*CNeuromod 2025*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Setup - hidden from presentation\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "src_dir = Path('..') / 'src'\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "from utils import (\n",
    "    get_sourcedata_path,\n",
    "    get_derivatives_path,\n",
    "    load_events,\n",
    "    get_session_runs,\n",
    "    load_lowlevel_confounds\n",
    ")\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Define constants\n",
    "SUBJECT = 'sub-01'\n",
    "SESSION = 'ses-010'\n",
    "TR = 1.49\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n\n## The CNeuromod Mario Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The CNeuromod Mario Dataset\n\n### A Naturalistic fMRI Paradigm\n\n**Participants:** 5 subjects playing Super Mario Bros (NES) in the scanner\n\n**Task:** Natural gameplay - no constraints on strategy or behavior\n\n**Levels:**\n- **22 levels:** exclusion of waterworld and Bowser levels for gameplay consistency.\n\n**Acquisition:**\n- TR = 1.49s (multiband fMRI)\n- ~5 runs per session\n- ~5 minutes per run (~200 volumes)\n- ~25 minutes total gameplay per session\n\n**Key insight:** Real-world complexity with rich behavioral structure\n\n<div style=\"background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-top: 20px;\">\n<b>Why naturalistic paradigms?</b><br>\nTraditional fMRI uses simple, repetitive tasks. Naturalistic paradigms like gameplay capture complex, dynamic behavior closer to real-world cognition.\n</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Analysis Pipeline Overview\n\n### Two Complementary Approaches\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         fMRI Data                                \u2502\n\u2502                    (BOLD time series)                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   GLM Analysis   \u2502         \u2502   RL Agent        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Hypothesis-driven\u2502         \u2502 Learned features  \u2502\n    \u2502 contrasts        \u2502         \u2502 (CNN activations) \u2502\n    \u2502 - LEFT vs RIGHT  \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n             \u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u2502                   \u2502 Ridge Encoding    \u2502\n             \u2502                   \u2502 (Predict BOLD)    \u2502\n             \u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502         Brain Activity Maps                    \u2502\n    \u2502    Which regions? What representations?        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**GLM:** Hand-crafted regressors \u2192 Interpretable contrasts\n\n**Encoding:** Learned representations \u2192 Predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Today's Focus: sub-01, ses-010\n\n### Single Session Deep Dive\n\n**Why single session?**\n- Laptop-friendly analysis (~30-45 min runtime)\n- Complete pipeline demonstration\n- Easy to extend to multiple subjects/sessions\n\n**Session details:**\n- 5 runs \u00d7 ~5 minutes = ~25 minutes gameplay\n- ~1000 fMRI volumes\n- ~200+ behavioral events\n\n**BIDS structure:**\n```\nsourcedata/\n\u251c\u2500\u2500 mario/                    # Raw fMRI\n\u251c\u2500\u2500 mario.fmriprep/          # Preprocessed BOLD\n\u251c\u2500\u2500 mario.annotations/       # Behavioral events\n\u251c\u2500\u2500 mario.replays/           # Game recordings (.bk2)\n\u2514\u2500\u2500 cneuromod.processed/     # Anatomical templates\n    \u2514\u2500\u2500 smriprep/\n        \u2514\u2500\u2500 sub-01/\n```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dataset Exploration\n\n## Rich Behavioral Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Behavioral Annotations\n\nThe `mario.annotations` dataset provides three types of events:\n\n**1. Action events (button presses):**\n- A, B, LEFT, RIGHT, UP, DOWN\n- Precise onset and duration\n- **Button mappings:**\n  - **A = JUMP** (short taps, mean duration ~0.3s)\n  - **B = RUN/FIREBALL** (held continuously, mean duration ~12s)\n  - LEFT/RIGHT = Movement\n  - UP = Enter pipe, DOWN = Crouch\n\n**2. Game events:**\n- Kill/stomp, Kill/kick (defeating enemies)\n- Hit/life_lost (player damage)\n- Powerup_collected, Coin_collected (rewards)\n- Flag_reached (level completion)\n\n**3. Scene information:**\n- Level segmentation\n- Unique scene codes for each game section\n\nLet's load and visualize these events!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load events for all runs in the session\n",
    "\n",
    "sourcedata_path = get_sourcedata_path()\n",
    "\n",
    "try:\n",
    "    runs = get_session_runs(SUBJECT, SESSION, sourcedata_path)\n",
    "    print(f\"Found {len(runs)} runs: {runs}\\n\")\n",
    "    \n",
    "    # Load all events\n",
    "    all_events = []\n",
    "    for run in runs:\n",
    "        events = load_events(SUBJECT, SESSION, run, sourcedata_path)\n",
    "        all_events.append(events)\n",
    "        print(f\"{run}: {len(events)} events\")\n",
    "    \n",
    "    session_events = pd.concat(all_events, ignore_index=True)\n",
    "    print(f\"\\nTotal events: {len(session_events)}\")\n",
    "    \n",
    "    # Categorize\n",
    "    button_events = ['A', 'B', 'LEFT', 'RIGHT', 'UP', 'DOWN']\n",
    "    game_events = ['Kill/stomp', 'Kill/kick', 'Hit/life_lost', \n",
    "                   'Powerup_collected', 'Coin_collected']\n",
    "    \n",
    "    n_buttons = len(session_events[session_events['trial_type'].isin(button_events)])\n",
    "    n_game = len(session_events[session_events['trial_type'].isin(game_events)])\n",
    "    \n",
    "    print(f\"\\nButton presses: {n_buttons}\")\n",
    "    print(f\"Game events: {n_game}\")\n",
    "    \n",
    "    # Top events\n",
    "    print(\"\\nTop 10 most frequent events:\")\n",
    "    print(session_events['trial_type'].value_counts().head(10))\n",
    "    \n",
    "    EVENTS_LOADED = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading events: {e}\")\n",
    "    print(\"Using demo data...\")\n",
    "    EVENTS_LOADED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize event frequencies\n",
    "\n",
    "from glm_utils import plot_event_frequencies\n",
    "\n",
    "fig = plot_event_frequencies(\n",
    "    session_events, n_buttons, n_game,\n",
    "    SUBJECT, SESSION\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Timeline Visualization\n\n**Goal:** Understand the temporal structure of gameplay\n\nWe'll visualize:\n- Button press patterns over time\n- Game event occurrences\n- Event density (actions per second)\n\n**What to look for:**\n- Clusters of activity (intense gameplay moments)\n- Gaps (deaths, level transitions)\n- Relationships between buttons and game events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Event timeline for first run\n",
    "\n",
    "from glm_utils import plot_event_timeline\n",
    "\n",
    "if EVENTS_LOADED and len(all_events) > 0:\n",
    "    fig = plot_event_timeline(all_events[0], runs[0], button_events)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Timeline not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Game Replay Data\n\n### Frame-by-frame recordings (.bk2 files)\n\n**What's in a replay?**\n- 60 Hz game frames\n- Button states for each frame\n- RAM variables: player position, score, lives, time, power-up state\n\n**Uses:**\n1. **RL training:** Extract frames as visual input for CNN\n2. **Validation:** Verify behavioral annotations\n3. **Visualization:** Show actual gameplay moments\n\n**For this tutorial:** We'll use simplified proxy features instead of full frame extraction (faster for demonstration)\n\n<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; margin-top: 20px;\">\n<b>Note:</b> Full replay processing requires BizHawk emulator and can extract ~18,000 frames per run. For efficiency, we use pre-computed features.\n</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "rise": {
   "autolaunch": false,
   "enable_chalkboard": true,
   "footer": "<h3>CNeuromod 2025</h3>",
   "header": "<h2>Mario fMRI Tutorial</h2>",
   "scroll": true,
   "slideNumber": true,
   "theme": "simple",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}